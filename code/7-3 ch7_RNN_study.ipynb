{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7-2 ch7_RNN_study.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lee7py/2021-py-DNN/blob/main/code/7-3%20ch7_RNN_study.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_qDfvmcn_Za"
      },
      "source": [
        "---\n",
        "title: \"Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)\"\n",
        "date: 2020-04-22T15:08:30+09:00\n",
        "tags:\n",
        "  - \"Deep Learning\"\n",
        "  - \"Python\"\n",
        "  - \"Google Colab\"\n",
        "  - \"Tensorflow 2.0\"\n",
        "  - \"Binary Classification\"\n",
        "  - \"Classification\"\n",
        "  - \"순환 신경망\"\n",
        "  - \"Recurrent Neural Network\"\n",
        "  - \"RNN\"\n",
        "  - \"SimpleRNN\"\n",
        "  - \"LSTM\"\n",
        "  - \"GRU\"\n",
        "  - \"텐서플로 2.0\"\n",
        "  - \"텐서플로 2.0 튜토리얼\"\n",
        "  - \"Image Augmentation\"\n",
        "  - \"Tensorflow 2.0 Tutorial\"\n",
        "categories:\n",
        "  - \"Deep Learning\"\n",
        "  - \"딥러닝\"\n",
        "  - \"텐서플로 2.0\"\n",
        "  - \"Python\"\n",
        "  - \"Tensorflow 2.0\"\n",
        "  - \"텐서플로 2.0 튜토리얼\"\n",
        "  - \"Tensorflow 2.0 Tutorial\"\n",
        "menu: \n",
        "  python:\n",
        "    name: Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)\n",
        "---\n",
        "\n",
        "## 공지\n",
        "\n",
        "- 본 Tutorial은 교재 `시작하세요 텐서플로 2.0 프로그래밍`의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다. \n",
        "\n",
        "- 강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다. \n",
        "\n",
        "![](/img/tensorflow2.0/book.jpg)<!-- -->\n",
        "\n",
        "\n",
        "- 본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. \n",
        "\n",
        "\n",
        "## Tutorial\n",
        "\n",
        "이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다. \n",
        "\n",
        "- [Google Colab Tensorflow 2.0 Installation](https://chloevan.github.io/python/tensorflow2.0/googlecolab/)\n",
        "- [Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수](https://chloevan.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/)\n",
        "- [Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성](https://chloevan.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/)\n",
        "- [Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크 - AND](https://chloevan.github.io/python/tensorflow2.0/ch3_3_3_network_and/)\n",
        "- [Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크 - OR](https://chloevan.github.io/python/tensorflow2.0/ch3_3_4_network_or/)\n",
        "- [Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR](https://chloevan.github.io/python/tensorflow2.0/ch3_3_5_network_xor/)\n",
        "- [Tensorflow 2.0 Tutorial ch4.1 - 선형회귀](https://chloevan.github.io/python/tensorflow2.0/ch4_1_linear_regression/)\n",
        "- [Tensorflow 2.0 Tutorial ch4.2 - 다항회귀](https://chloevan.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/)\n",
        "- [Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀](https://chloevan.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/)\n",
        "- [Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트](https://chloevan.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/)\n",
        "- [Tensorflow 2.0 Tutorial ch5.1 - 분류](https://chloevan.github.io/python/tensorflow2.0/ch5_1_binary_classification/)\n",
        "- [Tensorflow 2.0 Tutorial ch5.2 - 다항분류](https://chloevan.github.io/python/tensorflow2.0/ch5_2_multi_classification/)\n",
        "- [Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST](https://chloevan.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/)\n",
        "- [Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론](https://chloevan.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/)\n",
        "- [Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습](https://chloevan.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/)\n",
        "- [Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기](https://chloevan.github.io/python/tensorflow2.0/ch6_4_improve_performance/)\n",
        "\n",
        "\n",
        "## I. 개요\n",
        "\n",
        "순환 신경망(Recurrent Neural Network; RNN)은 지금까지 살펴본 네트워크와는 입력을 받아들이는 방식과 처리하는 방식에 약간 차이가 있습니다. 순환 신경망은 순서가 있는 데이터를 입력으로 받고, 같은 네트워크를 이용해 변화하는 입력에 대한 출력을 얻어냅니다. \n",
        "\n",
        "순서가 있는 데이터는 음악, 자연어, 날씨, 주가 등 시간의 흐름에 따라 변화하고 그 변화가 의미를 갖는 데이터입니다. \n",
        "\n",
        "## II. 순환 신경망의 구조\n",
        "\n",
        "우선 `CNN`과 `RNN`의 딥러닝 구조의 차이점에 대해 이미지[^1]로 확인하면 보다 직관적으로 이해가 될 수 있습니다. \n",
        "\n",
        "CNN의 구조는 본 교재를 계속 따라오셨다면 익숙하다시피, 아래와 같은 구조로 되어 있습니다. \n",
        "\n",
        "![](/img/tensorflow2.0/tutorial_07_01_2/tutorial_01_CNN.png)\n",
        "\n",
        "그러나, RNN의 구조는 아래에서 확인할 수 있는 것처럼, 순환 모양의 화살표가 있다는 것이 차이점입니다. \n",
        "\n",
        "![](/img/tensorflow2.0/tutorial_07_01_2/tutorial_01_RNN.png)\n",
        "\n",
        "순환 신경망의 특징에 대해 간단하게 요약하면 다음과 같습니다. \n",
        "- 입력 X를 받아서, 출력 Y를 반환합니다.\n",
        "- 순환구조를 가지고 있다; 어떤 레이어의 출력을 다시 입력으로 받는 구조를 말합니다. \n",
        "- 순환 신경망은 입력과 출력의 길이에 제한이 없습니다. \n",
        "- 순환 신경망은 이미지에 대한 설명을 생성하는 이미지 설명 생성, 문장의 긍정/부정을 판단하는 감성 분석, 하나의 언어를 다른 언어로 번역하는 기계 번역(Machine Translation) 등 다양한 용도로 활용됩니다. \n",
        "\n",
        "순환 신경망의 이론에 대한 자세한 설명은 교재 (`p. 174-5`)를 참조하시기를 바랍니다. \n",
        "\n",
        "## III. 주요 레이어 정리\n",
        "순환 신경망의 가장 기초적인 레이어는 `SimpleRNN` 레이어이며, 이 레이어에서 출발한 `LSTM` 레이어 또는 `GRU`레이어가 주로 쓰입니다. 그리고, 자연어 처리를 위해서 꼭 알아둬야 하는 임베딩(`Embedding`)레이어도 같이 알아봅니다. \n",
        "\n",
        "### (1) SimpleRNN 레이어\n",
        "`SimpleRNN`레이어는 가장 간단한 형태의 `RNN`레이업니다. 수식에 대한 설명은 교재(`p. 176`)를 참고합니다. 이 때 주로 사용되는 활성화 함수로는 `tanh`가 사용됩니다. `tanh`는 실수 입력을 받아 -1에서 1사이의 출력 값을 반환하는 활성하 함수이며, 이 활성화 함수 자리에 `ReLU`같은 다른 활성화함수를 쓸 수도 있습니다. \n",
        "\n",
        "`SimpleRNN` 레이어는 `tf.keras`에서 한 줄로 간단하게 생성이 가능합니다.\n",
        "\n",
        "```python\n",
        "rnn1 = tf.keras.layers.SimpleRNN(units=1, activation='tanh', return_sequences=True)\n",
        "```\n",
        "\n",
        "- `units`는 `SimpleRNN`의 레이어에 존재하는 뉴런의 수를 의미합니다. `return_sequences`는 출력으로 시퀀스 전체를 출력할지 여부를 나타내는 옵션이며, 여러 개의 `RNN 레이어`를 쌓을 때 쓰입니다. \n",
        "\n",
        "간단한 예제를 통해서 학습을 해봅니다. \n",
        "\n",
        "\n",
        "[^1]: Different between CNN，RNN（Quote） Retrieved from https://medium.com/@Aj.Cheng/different-between-cnn-rnn-quote-7c224795db58\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1gWw2ee1tMa"
      },
      "source": [
        "# 텐서플로 2 버전 선택\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm4jB5GQzUDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9fbebfa-fc94-403f-fed0-19db20ab5e9a"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in range(6):\n",
        "  # [0, 1, 2, 3], [1, 2, 3, 4]\n",
        "  lst = list(range(i,i+4))\n",
        "\n",
        "  # 위에서 구한 시퀀스의 숫자들을 각각 10으로 나눈 다음 저장합니다. \n",
        "  # SimpleRNN에 각 타임스텝에 하나씩 숫자가 들어가기 때문에 여기서도 하나씩 분리해서 배열에 저장합니다. \n",
        "  X.append(list(map(lambda c:[c/10], lst)))\n",
        "\n",
        "  # 정답에 해당하는 4, 5 등의 정수 역시 앞에서처럼 10으로 나눠서 저장합니다. \n",
        "  Y.append((i+4)/10)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(X)\n",
        "print(Y)\n",
        "print()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 4, 1)\n",
            "(6,)\n",
            "[[[0. ]\n",
            "  [0.1]\n",
            "  [0.2]\n",
            "  [0.3]]\n",
            "\n",
            " [[0.1]\n",
            "  [0.2]\n",
            "  [0.3]\n",
            "  [0.4]]\n",
            "\n",
            " [[0.2]\n",
            "  [0.3]\n",
            "  [0.4]\n",
            "  [0.5]]\n",
            "\n",
            " [[0.3]\n",
            "  [0.4]\n",
            "  [0.5]\n",
            "  [0.6]]\n",
            "\n",
            " [[0.4]\n",
            "  [0.5]\n",
            "  [0.6]\n",
            "  [0.7]]\n",
            "\n",
            " [[0.5]\n",
            "  [0.6]\n",
            "  [0.7]\n",
            "  [0.8]]]\n",
            "[0.4 0.5 0.6 0.7 0.8 0.9]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXCH1A6zEDlS",
        "outputId": "6b72b4e7-86a6-4977-9c0c-872456435c12"
      },
      "source": [
        "for i in range(len(X)): \n",
        "  print(X[i], Y[i])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. ]\n",
            " [0.1]\n",
            " [0.2]\n",
            " [0.3]] 0.4\n",
            "[[0.1]\n",
            " [0.2]\n",
            " [0.3]\n",
            " [0.4]] 0.5\n",
            "[[0.2]\n",
            " [0.3]\n",
            " [0.4]\n",
            " [0.5]] 0.6\n",
            "[[0.3]\n",
            " [0.4]\n",
            " [0.5]\n",
            " [0.6]] 0.7\n",
            "[[0.4]\n",
            " [0.5]\n",
            " [0.6]\n",
            " [0.7]] 0.8\n",
            "[[0.5]\n",
            " [0.6]\n",
            " [0.7]\n",
            " [0.8]] 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBicUhQXLrkp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a32b30-a1d0-49b3-a66d-d63d5526574f"
      },
      "source": [
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  print(X)\n",
        "  print(Y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 4, 1)\n",
            "(6,)\n",
            "[[[0. ]\n",
            "  [0.1]\n",
            "  [0.2]\n",
            "  [0.3]]\n",
            "\n",
            " [[0.1]\n",
            "  [0.2]\n",
            "  [0.3]\n",
            "  [0.4]]\n",
            "\n",
            " [[0.2]\n",
            "  [0.3]\n",
            "  [0.4]\n",
            "  [0.5]]\n",
            "\n",
            " [[0.3]\n",
            "  [0.4]\n",
            "  [0.5]\n",
            "  [0.6]]\n",
            "\n",
            " [[0.4]\n",
            "  [0.5]\n",
            "  [0.6]\n",
            "  [0.7]]\n",
            "\n",
            " [[0.5]\n",
            "  [0.6]\n",
            "  [0.7]\n",
            "  [0.8]]]\n",
            "[0.4 0.5 0.6 0.7 0.8 0.9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaGYEKxl-VUH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8ajfVcJ4o9i"
      },
      "source": [
        "이제 `SimpleRNN` 레이어를 사용한 네트워크를 정의합니다. 모델 구조는 지금까지 계속 봐온 시퀀셜 모델이고, 출력을 위한 `Dense` 레이어가 뒤에 추가되어 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU6FkwUD49JJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d581d2-a507-49b9-f057-3ae9ad84b6e4"
      },
      "source": [
        "# 7.3 시퀀스 예측 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(units=10, return_sequences=False, input_shape=[4,1]),\n",
        "    #tf.keras.layers.SimpleRNN(10, input_length=4, input_dim=1),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 10)                120       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 131\n",
            "Trainable params: 131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wakc-TmH5ZUV"
      },
      "source": [
        "여기에서 주목해야 하는 코드는 `input_shape`입니다. 여기에서 `[4,1]`은 각각 `timesteps`, `input_dim`을 나타냅니다. 타입스텝은(timesteps)이란 순환 신경망이 입력에 대해 계산을 반복하는 횟수를 말하고, `input_dim`은 벡터의 크기를 나타냅니다. \n",
        "\n",
        "```\n",
        "[[0. ]\n",
        " [0.1]\n",
        " [0.2]\n",
        " [0.3]] 0.4\n",
        "```\n",
        "\n",
        "두번째의 4는 타임스텝, 세번째의 1은 `input_dim`이 됩니다. 그림을 참조하면 훨씬 이해하기 쉽습니다. (교재, p.180)\n",
        "\n",
        "시퀀스 예측 모델은 4 타임스텝에 걸쳐 입력을 받고, 마지막에 출력값을 다음 레이어로 반환합니다. 우리가 추가한 `Dense`레이어에는 별도의 활성화함수가 없기 때문에 $h_{3}$는 바로 $y_{3}$이 됩니다. 그리고 이 값과 0.4와의 차이가 `mse`, 즉 평균 제곱 오차(`Mean Squared Error`)가 됩니다. \n",
        "\n",
        "이제 훈련을 시킵니다. 이 때, `verbose`값을 0으로 놓으면 훈련 과정에서의 출력이 나오지 않습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpFME3mM7tUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b412fb6e-9b12-488c-f3f6-422af5024f98"
      },
      "source": [
        "model.fit(X, Y, epochs=100, verbose=0)\n",
        "print(model.predict(X))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.39136913]\n",
            " [0.5137689 ]\n",
            " [0.6225732 ]\n",
            " [0.7166634 ]\n",
            " [0.79661   ]\n",
            " [0.8638736 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqGJUwnj8kCW"
      },
      "source": [
        "X가 주어졌을 때 학습된 모델이 시퀀스를 어떻게 예측하는지 확인해보면 얼추 비슷하게 예측하고 있음을 확인할 수 있습니다. 그렇다면 학습과정에서 본 적이 없는 테스트 데이터를 넣으면 어떨까요? `X`의 범위가 0.0~0.9 였으니, 양쪽으로 한 칸씩 더 나간 데이터를 입력합니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc1ADK7n83Ek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b54db38-df53-4a94-eb59-9db0e9972b3a"
      },
      "source": [
        "print(model.predict(np.array([[[0.6], [0.7], [0.8], [0.9]]])))\n",
        "print(model.predict(np.array([[[-0.1], [0.0], [0.1], [0.2]]])))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.92014825]]\n",
            "[[0.25870302]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF7gxAPOQI2J"
      },
      "source": [
        "문제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-l-thcAQIMb",
        "outputId": "9a7e34ff-1282-40b2-aabe-391ab7b3b94e"
      },
      "source": [
        "# 7.3 시퀀스 예측 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(units=6, return_sequences=False, input_shape=[4, 2]),\n",
        "    tf.keras.layers.Dense(3)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (None, 6)                 54        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 21        \n",
            "=================================================================\n",
            "Total params: 75\n",
            "Trainable params: 75\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKt0_Qe_QH8K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dMW7X6N9JpN"
      },
      "source": [
        "1을 예측하기를 원한 데이터의 출력으로는 0.91을 0.3을 예측하기 원한 데이터의 출력으로는 0.22의 값을 반환했습니다. \n",
        "\n",
        "실무에서는 `SimpleRNN`보다는 `LSTM` 레이어와 `GRU`레이어를 사용합니다. \n",
        "\n",
        "### (2) LSTM 레이어\n",
        "\n",
        "`SimpleRNN` 레이어에는 한 가지 치명적인 단점이 존재합니다. 입력 데이터가 길어질수록, 즉 데이터의 타임스텝이 길어질수록 학습 능력이 떨어진다는 점입니다. 이를 장기의존성(Long-Term Dependency)문제라고 하며, 입력 데이터와 출력 사이의 길이가 멀어질수록 연관 관계가 적어집니다. \n",
        "\n",
        "![](/img/tensorflow2.0/tutorial_07_01_2/tutorial_02_LongTermDependency.png)\n",
        "\n",
        "위 그림이 이러한 문제를 적절하게 표현한 것입니다. 입력 데이터가 길어지면 길어질수록 출력값의 연관 관계가 적어지는 것을 볼 수 있습니다. \n",
        "\n",
        "이러한 문제점을 해결하기 위해 `LSTM`이 제안 되었습니다.[^2] 셀로 나타낸 SimpleRNN과 LSTM의 계산 흐름을 보면 조금 이해가 될 것입니다. \n",
        "\n",
        "- 먼저 SimpleRNN의 그림은 아래와 같습니다. \n",
        "\n",
        "![](/img/tensorflow2.0/tutorial_07_01_2/tutorial_02_SimpleRNN.png)\n",
        "\n",
        "여기에서는 타임스텝의 방향으로 $h_{t}$만 전달되고 있음을 확인할 수 있습니다. \n",
        "\n",
        "![](/img/tensorflow2.0/tutorial_07_01_2/tutorial_02_LSTM.png)\n",
        "\n",
        "그런데, 여기에서는 셀 상테인 $c_{t}$가 평생선을 그리며 함께 전달되고 있습니다. 이처럼 타임스텝을 가로지르며 `LSTM` 셀 상태가 보존되기 때문에 장기의존성 문제를 해결할 수 있다는 것이 `LSTM`의 핵심 아이디어입니다. \n",
        "\n",
        "교재 184페이지를 보면 위 셀에 대한 수식이 존재합니다만, 수식에 대한 구체적인 이해가 자료가 필요하다면 크리스토퍼 올라(`Christopher Olah`)의 블로그 글을 참고합니다.[^3]\n",
        "\n",
        "`LSTM`의 학습 능력을 확인하기 위한 예제는 `LSTM`을 처음 제안한 논문에 나온 실험 여섯개 중 다섯 번째인 곱셈 문제(`Multiplication Problem`)입니다. 이 문제는 말 그대로 실수에 대해 곱셈을 하는 문제인데, 고려해야 할 실수의 범위가 100개이고 그 중에서 마킹된 두개의 숫자만 곱해야 한다는 특이한 문제입니다. \n",
        "\n",
        "[^2]: 1997년 셉 호흐라이터(Sepp Hochreiter) 유르겐 슈미트후버(Jurgen Schmidhuber)에 의해 제안됨, (S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural Computation, 1997. https://www.bioinf.jku.at/publications/older/2604.pdf \n",
        "\n",
        "[^3]: Olah, Christopher. “Understanding LSTM Networks.” Understanding LSTM Networks -- Colah's Blog, colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFzH05KBbX9R"
      },
      "source": [
        "# 텐서플로 2 버전 선택\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwswtlnMXDX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0555998-b2b4-4b8b-80a6-3b4f52be909d"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "for i in range(3000): \n",
        "  # 0 ~ 1 범위의 랜덤한 숫자 100개를 만듭니다. \n",
        "  lst = np.random.rand(100)\n",
        "\n",
        "  # 마킹할 숫자 2개의 인덱스를 뽑습니다. \n",
        "  idx = np.random.choice(100, 2, replace=False)\n",
        "\n",
        "  # 마킹 인덱스가 저장된 원-핫 인코딩 벡터를 만듭니다. \n",
        "  zeros=np.zeros(100)\n",
        "  zeros[idx]=1\n",
        "  \n",
        "  # 마킹 인덱스와 랜덤한 숫자를 합쳐서 X에 저장합니다. \n",
        "  X.append(np.array(list(zip(zeros, lst))))\n",
        "  # 마킹 인덱스가 1인 값만 서로 곱해서 Y에 저장합니다. \n",
        "  Y.append(np.prod(lst[idx]))\n",
        "\n",
        "print(X[0], Y[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.82460292]\n",
            " [0.         0.28347129]\n",
            " [0.         0.49241977]\n",
            " [0.         0.72153292]\n",
            " [0.         0.48083461]\n",
            " [0.         0.83429886]\n",
            " [1.         0.94081183]\n",
            " [0.         0.4513793 ]\n",
            " [0.         0.50638491]\n",
            " [0.         0.09614864]\n",
            " [0.         0.59529907]\n",
            " [0.         0.88268554]\n",
            " [0.         0.69571169]\n",
            " [0.         0.80730224]\n",
            " [0.         0.61231659]\n",
            " [0.         0.32058495]\n",
            " [0.         0.90422398]\n",
            " [0.         0.75802085]\n",
            " [0.         0.69330547]\n",
            " [0.         0.45260086]\n",
            " [0.         0.84193957]\n",
            " [0.         0.75551941]\n",
            " [0.         0.70327102]\n",
            " [0.         0.64814797]\n",
            " [0.         0.25072947]\n",
            " [0.         0.0479494 ]\n",
            " [0.         0.89582523]\n",
            " [0.         0.85455796]\n",
            " [0.         0.13373338]\n",
            " [0.         0.51017449]\n",
            " [0.         0.33156932]\n",
            " [0.         0.398899  ]\n",
            " [0.         0.77698567]\n",
            " [0.         0.37742786]\n",
            " [0.         0.47731346]\n",
            " [0.         0.77737904]\n",
            " [0.         0.63259562]\n",
            " [0.         0.01786874]\n",
            " [0.         0.21208832]\n",
            " [0.         0.58181901]\n",
            " [0.         0.42388702]\n",
            " [0.         0.3790882 ]\n",
            " [0.         0.91221032]\n",
            " [0.         0.38064806]\n",
            " [0.         0.09079002]\n",
            " [0.         0.58104318]\n",
            " [0.         0.85330473]\n",
            " [0.         0.78884011]\n",
            " [0.         0.86724254]\n",
            " [0.         0.42835835]\n",
            " [0.         0.17689785]\n",
            " [0.         0.97916401]\n",
            " [0.         0.85481439]\n",
            " [0.         0.03220802]\n",
            " [0.         0.34000682]\n",
            " [0.         0.2658701 ]\n",
            " [1.         0.82154844]\n",
            " [0.         0.68184933]\n",
            " [0.         0.37339306]\n",
            " [0.         0.47816777]\n",
            " [0.         0.43742428]\n",
            " [0.         0.62613951]\n",
            " [0.         0.82353386]\n",
            " [0.         0.61998014]\n",
            " [0.         0.34012521]\n",
            " [0.         0.28357227]\n",
            " [0.         0.5705621 ]\n",
            " [0.         0.25268245]\n",
            " [0.         0.07039436]\n",
            " [0.         0.21779698]\n",
            " [0.         0.18543429]\n",
            " [0.         0.99551594]\n",
            " [0.         0.30356335]\n",
            " [0.         0.92430608]\n",
            " [0.         0.62658644]\n",
            " [0.         0.72431249]\n",
            " [0.         0.70069946]\n",
            " [0.         0.86246243]\n",
            " [0.         0.5987213 ]\n",
            " [0.         0.46252667]\n",
            " [0.         0.83569129]\n",
            " [0.         0.45004718]\n",
            " [0.         0.55350158]\n",
            " [0.         0.32418474]\n",
            " [0.         0.80755003]\n",
            " [0.         0.91977209]\n",
            " [0.         0.41085337]\n",
            " [0.         0.39938699]\n",
            " [0.         0.09924916]\n",
            " [0.         0.3675234 ]\n",
            " [0.         0.47277321]\n",
            " [0.         0.84008068]\n",
            " [0.         0.08052757]\n",
            " [0.         0.24667248]\n",
            " [0.         0.11795476]\n",
            " [0.         0.53589551]\n",
            " [0.         0.40461709]\n",
            " [0.         0.67028177]\n",
            " [0.         0.04122961]\n",
            " [0.         0.13993474]] 0.7729224937644974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdcnvh2aY58c"
      },
      "source": [
        "입력된 값이 길지만, 1은 두번만 들어가 있기 때문에, 1이 찍인 원소를 찾습니다. `[1.    0.08361932]`과 `[1.         0.66439549]`이 확인이 됩니다. \n",
        "\n",
        "`0.08361932`와 `0.66439549`를 곱하면 `0.055556298045436`값이 나옵니다. `SimpleRNN` 레이어를 이용한 곱셈 문제 모델을 정의합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4sS-sjlaCWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87421fa4-d734-44a0-8a06-91e81b1480ef"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.SimpleRNN(units=30, return_sequences=True, input_shape=[100,2]), \n",
        "  tf.keras.layers.SimpleRNN(units=30), \n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 100, 30)           990       \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 30)                1830      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 2,851\n",
            "Trainable params: 2,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RnA6vqeaY7O"
      },
      "source": [
        "`RNN` 레이어를 겹치기 위해 첫 번째 `SimpleRNN`레이어에서 `return_sequences=True`로 설정된 것을 확인할 수 있습니다. `return_sequences`는 레이어의 출력을 다음 레이어로 그대로 넘겨주게 됩니다. \n",
        "\n",
        "겹치는 레이어의 구조에 대한 이론 설명은 교재 `188페이지`를 참조하시기를 바랍니다. `RNN`은 `CNN`보다 학습 시간이 오래 걸리는 편이기 때문에 반드시 가속기를 `GPU`로 바꿔줍니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mZ_ynLObBMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f51235d-f34a-4184-8234-6bbdaac6071d"
      },
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# 2560개의 데이터만 학습시킵니다. 검증 데이터는 20%로 저장합니다. \n",
        "history=model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "64/64 [==============================] - 10s 107ms/step - loss: 0.0953 - val_loss: 0.0467\n",
            "Epoch 2/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0480 - val_loss: 0.0474\n",
            "Epoch 3/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0477 - val_loss: 0.0448\n",
            "Epoch 4/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0481 - val_loss: 0.0447\n",
            "Epoch 5/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0473 - val_loss: 0.0453\n",
            "Epoch 6/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0471 - val_loss: 0.0442\n",
            "Epoch 7/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0479 - val_loss: 0.0492\n",
            "Epoch 8/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0475 - val_loss: 0.0441\n",
            "Epoch 9/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0477 - val_loss: 0.0441\n",
            "Epoch 10/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0474 - val_loss: 0.0450\n",
            "Epoch 11/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0469 - val_loss: 0.0456\n",
            "Epoch 12/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0470 - val_loss: 0.0457\n",
            "Epoch 13/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0482 - val_loss: 0.0461\n",
            "Epoch 14/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0475 - val_loss: 0.0459\n",
            "Epoch 15/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0476 - val_loss: 0.0494\n",
            "Epoch 16/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0475 - val_loss: 0.0445\n",
            "Epoch 17/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0465 - val_loss: 0.0443\n",
            "Epoch 18/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0462 - val_loss: 0.0442\n",
            "Epoch 19/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0468 - val_loss: 0.0469\n",
            "Epoch 20/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0461 - val_loss: 0.0448\n",
            "Epoch 21/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0468 - val_loss: 0.0456\n",
            "Epoch 22/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0475 - val_loss: 0.0454\n",
            "Epoch 23/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0462 - val_loss: 0.0473\n",
            "Epoch 24/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0467 - val_loss: 0.0470\n",
            "Epoch 25/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0468 - val_loss: 0.0460\n",
            "Epoch 26/100\n",
            "64/64 [==============================] - 7s 107ms/step - loss: 0.0461 - val_loss: 0.0443\n",
            "Epoch 27/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0464 - val_loss: 0.0450\n",
            "Epoch 28/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0461 - val_loss: 0.0471\n",
            "Epoch 29/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0462 - val_loss: 0.0453\n",
            "Epoch 30/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0463 - val_loss: 0.0484\n",
            "Epoch 31/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0463 - val_loss: 0.0457\n",
            "Epoch 32/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0451 - val_loss: 0.0461\n",
            "Epoch 33/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0455 - val_loss: 0.0464\n",
            "Epoch 34/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0452 - val_loss: 0.0483\n",
            "Epoch 35/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0464 - val_loss: 0.0466\n",
            "Epoch 36/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0461 - val_loss: 0.0474\n",
            "Epoch 37/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0455 - val_loss: 0.0476\n",
            "Epoch 38/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0458 - val_loss: 0.0455\n",
            "Epoch 39/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0444 - val_loss: 0.0467\n",
            "Epoch 40/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0446 - val_loss: 0.0450\n",
            "Epoch 41/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0438 - val_loss: 0.0513\n",
            "Epoch 42/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0445 - val_loss: 0.0476\n",
            "Epoch 43/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0443 - val_loss: 0.0526\n",
            "Epoch 44/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0446 - val_loss: 0.0463\n",
            "Epoch 45/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0433 - val_loss: 0.0481\n",
            "Epoch 46/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0434 - val_loss: 0.0476\n",
            "Epoch 47/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0431 - val_loss: 0.0477\n",
            "Epoch 48/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0424 - val_loss: 0.0463\n",
            "Epoch 49/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0426 - val_loss: 0.0489\n",
            "Epoch 50/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0426 - val_loss: 0.0485\n",
            "Epoch 51/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0414 - val_loss: 0.0482\n",
            "Epoch 52/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0425 - val_loss: 0.0507\n",
            "Epoch 53/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0420 - val_loss: 0.0547\n",
            "Epoch 54/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0412 - val_loss: 0.0505\n",
            "Epoch 55/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0409 - val_loss: 0.0494\n",
            "Epoch 56/100\n",
            "64/64 [==============================] - 6s 102ms/step - loss: 0.0410 - val_loss: 0.0503\n",
            "Epoch 57/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0404 - val_loss: 0.0499\n",
            "Epoch 58/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0400 - val_loss: 0.0484\n",
            "Epoch 59/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0395 - val_loss: 0.0496\n",
            "Epoch 60/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0397 - val_loss: 0.0525\n",
            "Epoch 61/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0393 - val_loss: 0.0534\n",
            "Epoch 62/100\n",
            "64/64 [==============================] - 7s 101ms/step - loss: 0.0378 - val_loss: 0.0527\n",
            "Epoch 63/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0387 - val_loss: 0.0508\n",
            "Epoch 64/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0383 - val_loss: 0.0481\n",
            "Epoch 65/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0374 - val_loss: 0.0524\n",
            "Epoch 66/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0374 - val_loss: 0.0520\n",
            "Epoch 67/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0373 - val_loss: 0.0509\n",
            "Epoch 68/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0365 - val_loss: 0.0553\n",
            "Epoch 69/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0361 - val_loss: 0.0523\n",
            "Epoch 70/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0351 - val_loss: 0.0527\n",
            "Epoch 71/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0350 - val_loss: 0.0503\n",
            "Epoch 72/100\n",
            "64/64 [==============================] - 7s 106ms/step - loss: 0.0357 - val_loss: 0.0485\n",
            "Epoch 73/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0352 - val_loss: 0.0527\n",
            "Epoch 74/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0355 - val_loss: 0.0525\n",
            "Epoch 75/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0336 - val_loss: 0.0520\n",
            "Epoch 76/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0337 - val_loss: 0.0561\n",
            "Epoch 77/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0329 - val_loss: 0.0571\n",
            "Epoch 78/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0325 - val_loss: 0.0608\n",
            "Epoch 79/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0329 - val_loss: 0.0566\n",
            "Epoch 80/100\n",
            "64/64 [==============================] - 6s 101ms/step - loss: 0.0325 - val_loss: 0.0549\n",
            "Epoch 81/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0320 - val_loss: 0.0589\n",
            "Epoch 82/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0310 - val_loss: 0.0624\n",
            "Epoch 83/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0315 - val_loss: 0.0558\n",
            "Epoch 84/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0311 - val_loss: 0.0632\n",
            "Epoch 85/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0307 - val_loss: 0.0549\n",
            "Epoch 86/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0314 - val_loss: 0.0588\n",
            "Epoch 87/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0304 - val_loss: 0.0577\n",
            "Epoch 88/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0299 - val_loss: 0.0562\n",
            "Epoch 89/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0296 - val_loss: 0.0578\n",
            "Epoch 90/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0296 - val_loss: 0.0602\n",
            "Epoch 91/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0282 - val_loss: 0.0572\n",
            "Epoch 92/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0281 - val_loss: 0.0576\n",
            "Epoch 93/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0274 - val_loss: 0.0630\n",
            "Epoch 94/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0279 - val_loss: 0.0659\n",
            "Epoch 95/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0283 - val_loss: 0.0590\n",
            "Epoch 96/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0284 - val_loss: 0.0608\n",
            "Epoch 97/100\n",
            "64/64 [==============================] - 7s 103ms/step - loss: 0.0269 - val_loss: 0.0656\n",
            "Epoch 98/100\n",
            "64/64 [==============================] - 7s 105ms/step - loss: 0.0265 - val_loss: 0.0598\n",
            "Epoch 99/100\n",
            "64/64 [==============================] - 7s 104ms/step - loss: 0.0256 - val_loss: 0.0600\n",
            "Epoch 100/100\n",
            "64/64 [==============================] - 7s 102ms/step - loss: 0.0259 - val_loss: 0.0593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xEw56Lvbof2"
      },
      "source": [
        "훈련 데이터의 손실(`loss`)과 검증 데이터의 손실(`var_loss`)는 감소하지 않고 오히려 증가하는 것 같습니다. 경향을 직관적으로 파악하기 위해 `history` 변수에 저장된 값으로 그래프를 그려봅니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZapF9f-yb-KJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "76eae92d-b0ca-427c-fea6-add266528bb9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLoCsg7hcHAf"
      },
      "source": [
        "학습 결과는 전형적인 과적합 그래프를 보여줍니다. 테스트 데이터에 대한 예측은 어떨까요? 논문에서는 오차가 0.04 이상일 때 오답으로 처리합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQh_p6-Mdvgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42bb91c6-1bdd-4b2d-f2ab-6952f1548f6f"
      },
      "source": [
        "model.evaluate(X[2560:], Y[2560:])\n",
        "prediction=model.predict(X[2560:2560+5])\n",
        "\n",
        "# 5개 테스트 데이터에 대한 예측을 표시합니다. \n",
        "for i in range(5): \n",
        "  print(Y[2560+i], '\\t', prediction[i][0], '\\tdiff:', abs(prediction[i][0] - Y[2560+i]))\n",
        "\n",
        "prediction = model.predict(X[2560:])\n",
        "fail = 0\n",
        "for i in range(len(prediction)):\n",
        "  # 오차가 0.04 이상이면 오답입니다. \n",
        "  if abs(prediction[i][0] - Y[2560+i]) > 0.04:\n",
        "    fail +=1\n",
        "\n",
        "print('correctness:', (440-fail)/440*100, '%')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0686\n",
            "0.07452410023946204 \t 0.30821636 \tdiff: 0.23369226295214257\n",
            "0.5442782526262651 \t 0.30749625 \tdiff: 0.23678200295051433\n",
            "0.6490257170556615 \t 0.32956606 \tdiff: 0.31945965555892686\n",
            "0.21367198378502533 \t 0.59582114 \tdiff: 0.38214915841162994\n",
            "0.6152284992315684 \t 0.3234848 \tdiff: 0.2917436910250102\n",
            "correctness: 12.272727272727273 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q27ljmgLe9Yx"
      },
      "source": [
        "먼저 전체에 대한 평가는 `0.0667`의 `loss`가 나왔습니다. 위에서 본 100번째의 에포크의 `val_loss`인 `0.0664`보다도 높은 값으로, 네트워크가 학습 과정에서 한번도 못 본 테스트 데이터에 대해서는 잘 예측하지 못합니다. 5개의 테스트 데이터에 대한 샘플은 오차가 `0.01`에서 `0.18`까지 다양하게 나타나며, 가장 중요한 정확도는 `12.72`로 확인 됩니다. \n",
        "\n",
        "그렇다면 `LSTM`레이어는 어떨까요? 이 문제를 풀기 위해 시퀀셜 모델을 정의합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOgxXjCLh48d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e9d0078-f240-4bc0-ae0c-e608cd994035"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.LSTM(units=30, return_sequences=True, input_shape=[100,2]), \n",
        "  tf.keras.layers.LSTM(units=30), \n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100, 30)           3960      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 30)                7320      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 11,311\n",
            "Trainable params: 11,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFfHHPbGi8mW"
      },
      "source": [
        "차이점은 `SimpleRNN`을 `LSTM`으로 바꾼 것 뿐입니다. 네트워크의 학습코드도 동일합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0ocxwtgjFXF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c40868ae-5c19-4f63-a647-2fc45991781c"
      },
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# 2560개의 데이터만 학습시킵니다. 검증 데이터는 20%로 저장합니다. \n",
        "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "64/64 [==============================] - 7s 19ms/step - loss: 0.0486 - val_loss: 0.0433\n",
            "Epoch 2/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0471 - val_loss: 0.0431\n",
            "Epoch 3/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0469 - val_loss: 0.0430\n",
            "Epoch 4/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0470 - val_loss: 0.0433\n",
            "Epoch 5/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0469 - val_loss: 0.0430\n",
            "Epoch 6/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0471 - val_loss: 0.0430\n",
            "Epoch 7/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0466 - val_loss: 0.0433\n",
            "Epoch 8/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0466 - val_loss: 0.0435\n",
            "Epoch 9/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0467 - val_loss: 0.0436\n",
            "Epoch 10/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0465 - val_loss: 0.0429\n",
            "Epoch 11/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0465 - val_loss: 0.0429\n",
            "Epoch 12/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0465 - val_loss: 0.0431\n",
            "Epoch 13/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0462 - val_loss: 0.0434\n",
            "Epoch 14/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0465 - val_loss: 0.0431\n",
            "Epoch 15/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0465 - val_loss: 0.0429\n",
            "Epoch 16/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0467 - val_loss: 0.0429\n",
            "Epoch 17/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0462 - val_loss: 0.0432\n",
            "Epoch 18/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0462 - val_loss: 0.0429\n",
            "Epoch 19/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0464 - val_loss: 0.0433\n",
            "Epoch 20/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0463 - val_loss: 0.0431\n",
            "Epoch 21/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0461 - val_loss: 0.0430\n",
            "Epoch 22/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0464 - val_loss: 0.0428\n",
            "Epoch 23/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0462 - val_loss: 0.0432\n",
            "Epoch 24/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0462 - val_loss: 0.0429\n",
            "Epoch 25/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0462 - val_loss: 0.0432\n",
            "Epoch 26/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0460 - val_loss: 0.0427\n",
            "Epoch 27/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0461 - val_loss: 0.0430\n",
            "Epoch 28/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0460 - val_loss: 0.0428\n",
            "Epoch 29/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0453 - val_loss: 0.0408\n",
            "Epoch 30/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0453 - val_loss: 0.0428\n",
            "Epoch 31/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0443 - val_loss: 0.0433\n",
            "Epoch 32/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0446 - val_loss: 0.0412\n",
            "Epoch 33/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0453 - val_loss: 0.0436\n",
            "Epoch 34/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0520 - val_loss: 0.0455\n",
            "Epoch 35/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0473 - val_loss: 0.0448\n",
            "Epoch 36/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0477 - val_loss: 0.0437\n",
            "Epoch 37/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0470 - val_loss: 0.0457\n",
            "Epoch 38/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0477 - val_loss: 0.0431\n",
            "Epoch 39/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0464 - val_loss: 0.0428\n",
            "Epoch 40/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0459 - val_loss: 0.0427\n",
            "Epoch 41/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0453 - val_loss: 0.0416\n",
            "Epoch 42/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0456 - val_loss: 0.0415\n",
            "Epoch 43/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0330 - val_loss: 0.0304\n",
            "Epoch 44/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0241 - val_loss: 0.0210\n",
            "Epoch 45/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0160 - val_loss: 0.0125\n",
            "Epoch 46/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0097 - val_loss: 0.0129\n",
            "Epoch 47/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0101 - val_loss: 0.0108\n",
            "Epoch 48/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0054 - val_loss: 0.0048\n",
            "Epoch 49/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0062 - val_loss: 0.0056\n",
            "Epoch 50/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0040 - val_loss: 0.0085\n",
            "Epoch 51/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0035 - val_loss: 0.0030\n",
            "Epoch 52/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0028 - val_loss: 0.0020\n",
            "Epoch 53/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0020\n",
            "Epoch 54/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 55/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 0.0014\n",
            "Epoch 56/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 57/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 58/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 59/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 60/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0013\n",
            "Epoch 61/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 8.3843e-04\n",
            "Epoch 62/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0010\n",
            "Epoch 63/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 8.6461e-04 - val_loss: 0.0011\n",
            "Epoch 64/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 9.0793e-04 - val_loss: 0.0012\n",
            "Epoch 65/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 8.6014e-04 - val_loss: 6.3696e-04\n",
            "Epoch 66/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 67/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 9.1274e-04 - val_loss: 0.0013\n",
            "Epoch 68/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 8.9899e-04 - val_loss: 6.6245e-04\n",
            "Epoch 69/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 7.3426e-04 - val_loss: 8.7849e-04\n",
            "Epoch 70/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 6.6769e-04 - val_loss: 0.0011\n",
            "Epoch 71/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 7.8482e-04 - val_loss: 9.1407e-04\n",
            "Epoch 72/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 9.4997e-04\n",
            "Epoch 73/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 7.6428e-04 - val_loss: 0.0010\n",
            "Epoch 74/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 9.2657e-04 - val_loss: 8.6567e-04\n",
            "Epoch 75/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 6.5576e-04 - val_loss: 7.9445e-04\n",
            "Epoch 76/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 7.8435e-04 - val_loss: 6.5532e-04\n",
            "Epoch 77/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 6.8152e-04 - val_loss: 8.5425e-04\n",
            "Epoch 78/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 6.7467e-04 - val_loss: 5.6509e-04\n",
            "Epoch 79/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 5.4216e-04 - val_loss: 7.4651e-04\n",
            "Epoch 80/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 5.5191e-04 - val_loss: 5.2764e-04\n",
            "Epoch 81/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 8.7011e-04 - val_loss: 4.8811e-04\n",
            "Epoch 82/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.3392e-04 - val_loss: 6.3331e-04\n",
            "Epoch 83/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 5.2300e-04 - val_loss: 5.3082e-04\n",
            "Epoch 84/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 5.2494e-04 - val_loss: 9.4121e-04\n",
            "Epoch 85/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.9192e-04 - val_loss: 6.3150e-04\n",
            "Epoch 86/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 5.1297e-04 - val_loss: 5.6614e-04\n",
            "Epoch 87/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.1150e-04 - val_loss: 4.7278e-04\n",
            "Epoch 88/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.8894e-04 - val_loss: 6.9004e-04\n",
            "Epoch 89/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.2007e-04 - val_loss: 3.7468e-04\n",
            "Epoch 90/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 9.4748e-04 - val_loss: 0.0011\n",
            "Epoch 91/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 8.5231e-04\n",
            "Epoch 92/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 6.1070e-04 - val_loss: 7.4505e-04\n",
            "Epoch 93/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.2324e-04 - val_loss: 4.2875e-04\n",
            "Epoch 94/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.9245e-04 - val_loss: 2.9359e-04\n",
            "Epoch 95/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 6.8605e-04 - val_loss: 3.5994e-04\n",
            "Epoch 96/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.0870e-04 - val_loss: 3.6277e-04\n",
            "Epoch 97/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 9.5216e-04 - val_loss: 0.0035\n",
            "Epoch 98/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 3.9078e-04\n",
            "Epoch 99/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.9026e-04 - val_loss: 9.0379e-04\n",
            "Epoch 100/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 8.8159e-04 - val_loss: 5.0316e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-1H4KDojOJT"
      },
      "source": [
        "`loss`와 `val_loss`는 40에포크를 넘어가면서 매우 가파르게 줄어들어 0에 가까워집니다. `val_loss`는 변동폭이 `loss`보다 크지만 전체적으로는 계속 감소하는 경향을 보입니다. 학습이 매우 잘 된 것으로 보입니다.\n",
        "\n",
        "이번에는 실제로 테스트 데이터에 얼마나 정확하게 값을 예측하는지 확인해봅니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzYco1QpoTl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f55b592-0b6c-4ea3-e355-5a068cab1c27"
      },
      "source": [
        "model.evaluate(X[2560:], Y[2560:])\n",
        "prediction=model.predict(X[2560:2560+5])\n",
        "\n",
        "# 5개 테스트 데이터에 대한 예측을 표시합니다. \n",
        "for i in range(5): \n",
        "  print(Y[2560+i], '\\t', prediction[i][0], '\\tdiff:', abs(prediction[i][0] - Y[2560+i]))\n",
        "\n",
        "prediction = model.predict(X[2560:])\n",
        "fail = 0\n",
        "for i in range(len(prediction)):\n",
        "  # 오차가 0.04 이상이면 오답입니다. \n",
        "  if abs(prediction[i][0] - Y[2560+i]) > 0.04:\n",
        "    fail +=1\n",
        "\n",
        "print('correctness:', (440-fail)/440*100, '%')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 1s 7ms/step - loss: 7.3699e-04\n",
            "0.07452410023946204 \t 0.07839883 \tdiff: 0.003874730949216698\n",
            "0.5442782526262651 \t 0.5354334 \tdiff: 0.008844841028059491\n",
            "0.6490257170556615 \t 0.6279767 \tdiff: 0.021049001490933694\n",
            "0.21367198378502533 \t 0.2269955 \tdiff: 0.013323514156945493\n",
            "0.6152284992315684 \t 0.6188294 \tdiff: 0.00360092991805927\n",
            "correctness: 90.68181818181819 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIplmAzGoXTf"
      },
      "source": [
        "테스트 데이터에 대한 `loss`는 0에 가까운 값이 나오고, 다섯 개의 샘플에 대한 오차도 0.04를 넘는 값이 없습니다. 또한 정확도 역시, 95.9%로 거의 96%에 가까운 것을 확인할 수 있습니다. \n",
        "\n",
        "곱셈문제를 푸는데 있어서 `LSTM`이 보다 적합하다는 것을 알 수 있습니다. \n",
        "\n",
        "다음 포스트에서는 `GRU`레이어와 `임베딩`레이어에 대해 학습하도록 합니다. \n",
        "\n",
        "## IV. 연습 파일\n",
        "- [구글 Colab에서 직접 연습해보자](https://colab.research.google.com/github/chloevan/deeplearningAI/blob/master/tensorflow2.0/ch7_1_2_RNN_theory(1).ipynb) \n",
        "\n",
        "## VI. Reference\n",
        "\n",
        "김환희. (2020). 시작하세요! 텐서플로 2.0 프로그래밍: 기초 이론부터 실전 예제까지 한번에 끝내는 머신러닝, 딥러닝 핵심 가이드. 서울: 위키북스."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHUp8LwBMk2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d91770b1-ded2-40f0-d94e-20a2492c1766"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(units=2, input_shape=[4,1], return_sequences=False),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_2 (SimpleRNN)     (None, 2)                 8         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 11\n",
            "Trainable params: 11\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNPPpoyvMk8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d07f09-332d-46f3-ac6d-3b5971829501"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(units=3, input_shape=[4,1], return_sequences=True),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_3 (SimpleRNN)     (None, 4, 3)              15        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4, 1)              4         \n",
            "=================================================================\n",
            "Total params: 19\n",
            "Trainable params: 19\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzq2f4KDMk_p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "23b78a1f-c582-4e79-90fe-7a4f99204f7f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(units=10, input_shape=[4,3], return_sequences=False),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_15 (SimpleRNN)    (None, 10)                140       \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 162\n",
            "Trainable params: 162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXyCExb4Mk5x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouqUbGJwMksB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98fd2679-2248-46b9-ffd4-0e4a09c864bd"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.GRU(units=30, return_sequences=True, input_shape=[100,2]), \n",
        "  tf.keras.layers.GRU(units=30), \n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 100, 30)           3060      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 30)                5580      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 8,671\n",
            "Trainable params: 8,671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie26H-chtmHn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f207409a-cf16-44a8-824e-55172b03046b"
      },
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# 2560개의 데이터만 학습시킵니다. 검증 데이터는 20%로 저장합니다. \n",
        "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "64/64 [==============================] - 3s 18ms/step - loss: 0.0497 - val_loss: 0.0456\n",
            "Epoch 2/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0473 - val_loss: 0.0438\n",
            "Epoch 3/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0468 - val_loss: 0.0432\n",
            "Epoch 4/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0472 - val_loss: 0.0430\n",
            "Epoch 5/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0467 - val_loss: 0.0429\n",
            "Epoch 6/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0469 - val_loss: 0.0429\n",
            "Epoch 7/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0467 - val_loss: 0.0427\n",
            "Epoch 8/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0464 - val_loss: 0.0427\n",
            "Epoch 9/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0466 - val_loss: 0.0427\n",
            "Epoch 10/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0464 - val_loss: 0.0431\n",
            "Epoch 11/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0463 - val_loss: 0.0431\n",
            "Epoch 12/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0464 - val_loss: 0.0435\n",
            "Epoch 13/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0464 - val_loss: 0.0434\n",
            "Epoch 14/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0458 - val_loss: 0.0431\n",
            "Epoch 15/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0459 - val_loss: 0.0422\n",
            "Epoch 16/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0452 - val_loss: 0.0419\n",
            "Epoch 17/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0455 - val_loss: 0.0415\n",
            "Epoch 18/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0448 - val_loss: 0.0410\n",
            "Epoch 19/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0432 - val_loss: 0.0480\n",
            "Epoch 20/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0454 - val_loss: 0.0393\n",
            "Epoch 21/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0374 - val_loss: 0.0243\n",
            "Epoch 22/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0117 - val_loss: 0.0049\n",
            "Epoch 23/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0033\n",
            "Epoch 24/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0023\n",
            "Epoch 25/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 26/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 27/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0014\n",
            "Epoch 28/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 29/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 30/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 31/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 32/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 9.5986e-04\n",
            "Epoch 33/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 9.5707e-04 - val_loss: 9.9842e-04\n",
            "Epoch 34/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 9.9248e-04 - val_loss: 0.0013\n",
            "Epoch 35/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 8.9517e-04 - val_loss: 8.4350e-04\n",
            "Epoch 36/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 8.2034e-04 - val_loss: 9.0554e-04\n",
            "Epoch 37/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 7.2940e-04 - val_loss: 8.1119e-04\n",
            "Epoch 38/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 6.8138e-04 - val_loss: 7.2171e-04\n",
            "Epoch 39/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 6.9222e-04 - val_loss: 6.6541e-04\n",
            "Epoch 40/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 7.9207e-04 - val_loss: 0.0016\n",
            "Epoch 41/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 6.6026e-04\n",
            "Epoch 42/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 5.7908e-04 - val_loss: 6.6932e-04\n",
            "Epoch 43/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 5.5926e-04 - val_loss: 6.9294e-04\n",
            "Epoch 44/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 6.0201e-04 - val_loss: 6.9941e-04\n",
            "Epoch 45/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 5.4749e-04 - val_loss: 4.8611e-04\n",
            "Epoch 46/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 5.1287e-04 - val_loss: 5.2295e-04\n",
            "Epoch 47/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 5.2824e-04 - val_loss: 4.9549e-04\n",
            "Epoch 48/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.9008e-04 - val_loss: 4.5760e-04\n",
            "Epoch 49/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 6.4088e-04 - val_loss: 5.4523e-04\n",
            "Epoch 50/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.4884e-04 - val_loss: 4.3700e-04\n",
            "Epoch 51/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.8442e-04 - val_loss: 6.5361e-04\n",
            "Epoch 52/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.9057e-04 - val_loss: 4.8917e-04\n",
            "Epoch 53/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.9268e-04 - val_loss: 4.5872e-04\n",
            "Epoch 54/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.8379e-04 - val_loss: 4.0201e-04\n",
            "Epoch 55/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.7685e-04 - val_loss: 4.1738e-04\n",
            "Epoch 56/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.9064e-04 - val_loss: 3.2601e-04\n",
            "Epoch 57/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.7130e-04 - val_loss: 3.2725e-04\n",
            "Epoch 58/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.4665e-04 - val_loss: 6.5472e-04\n",
            "Epoch 59/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.4611e-04 - val_loss: 3.0783e-04\n",
            "Epoch 60/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.8167e-04 - val_loss: 3.5403e-04\n",
            "Epoch 61/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.8498e-04 - val_loss: 2.9332e-04\n",
            "Epoch 62/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.0684e-04 - val_loss: 3.6992e-04\n",
            "Epoch 63/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.9208e-04 - val_loss: 2.9199e-04\n",
            "Epoch 64/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.5497e-04 - val_loss: 3.3979e-04\n",
            "Epoch 65/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.1827e-04 - val_loss: 2.8640e-04\n",
            "Epoch 66/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.1111e-04 - val_loss: 2.5847e-04\n",
            "Epoch 67/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.7087e-04 - val_loss: 4.0509e-04\n",
            "Epoch 68/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.5259e-04 - val_loss: 2.1806e-04\n",
            "Epoch 69/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.6366e-04 - val_loss: 3.2961e-04\n",
            "Epoch 70/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.3923e-04 - val_loss: 2.1558e-04\n",
            "Epoch 71/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.4100e-04 - val_loss: 3.0297e-04\n",
            "Epoch 72/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.3574e-04 - val_loss: 2.4356e-04\n",
            "Epoch 73/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.3385e-04 - val_loss: 2.4156e-04\n",
            "Epoch 74/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.0322e-04 - val_loss: 2.1251e-04\n",
            "Epoch 75/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.9235e-04 - val_loss: 1.9974e-04\n",
            "Epoch 76/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.3859e-04 - val_loss: 2.1835e-04\n",
            "Epoch 77/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.8480e-04 - val_loss: 2.3875e-04\n",
            "Epoch 78/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.6326e-04 - val_loss: 1.9413e-04\n",
            "Epoch 79/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.8044e-04 - val_loss: 1.6161e-04\n",
            "Epoch 80/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.6497e-04 - val_loss: 1.6837e-04\n",
            "Epoch 81/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.9295e-04 - val_loss: 1.6537e-04\n",
            "Epoch 82/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.9195e-04 - val_loss: 2.7784e-04\n",
            "Epoch 83/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.1022e-04 - val_loss: 2.3976e-04\n",
            "Epoch 84/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.7898e-04 - val_loss: 1.6829e-04\n",
            "Epoch 85/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.1850e-04 - val_loss: 1.9659e-04\n",
            "Epoch 86/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.2812e-04 - val_loss: 1.5346e-04\n",
            "Epoch 87/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.6108e-04 - val_loss: 2.2689e-04\n",
            "Epoch 88/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.8497e-04 - val_loss: 1.7380e-04\n",
            "Epoch 89/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.5304e-04 - val_loss: 1.5728e-04\n",
            "Epoch 90/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.4946e-04 - val_loss: 2.6403e-04\n",
            "Epoch 91/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.6234e-04 - val_loss: 1.4648e-04\n",
            "Epoch 92/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.8202e-04 - val_loss: 3.9157e-04\n",
            "Epoch 93/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.6106e-04 - val_loss: 1.2956e-04\n",
            "Epoch 94/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.5291e-04 - val_loss: 1.6106e-04\n",
            "Epoch 95/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.3036e-04 - val_loss: 1.4725e-04\n",
            "Epoch 96/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.5018e-04 - val_loss: 1.6663e-04\n",
            "Epoch 97/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.2584e-04 - val_loss: 1.6324e-04\n",
            "Epoch 98/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.2172e-04 - val_loss: 2.3369e-04\n",
            "Epoch 99/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.4374e-04 - val_loss: 1.0858e-04\n",
            "Epoch 100/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.1967e-04 - val_loss: 1.2749e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9PN1M1XtmMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac43d63d-963c-4b3a-881e-a10ad89dd773"
      },
      "source": [
        "model.evaluate(X[2560:], Y[2560:])\n",
        "prediction=model.predict(X[2560:2560+5])\n",
        "\n",
        "# 5개 테스트 데이터에 대한 예측을 표시합니다. \n",
        "for i in range(5): \n",
        "  print(Y[2560+i], '\\t', prediction[i][0], '\\tdiff:', abs(prediction[i][0] - Y[2560+i]))\n",
        "\n",
        "prediction = model.predict(X[2560:])\n",
        "fail = 0\n",
        "for i in range(len(prediction)):\n",
        "  # 오차가 0.04 이상이면 오답입니다. \n",
        "  if abs(prediction[i][0] - Y[2560+i]) > 0.04:\n",
        "    fail +=1\n",
        "\n",
        "print('correctness:', (440-fail)/440*100, '%')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 1s 7ms/step - loss: 1.8656e-04\n",
            "0.07452410023946204 \t 0.07412917 \tdiff: 0.0003949285699788585\n",
            "0.5442782526262651 \t 0.54292804 \tdiff: 0.0013502125986466496\n",
            "0.6490257170556615 \t 0.6633603 \tdiff: 0.014334580624239646\n",
            "0.21367198378502533 \t 0.21885759 \tdiff: 0.005185602598794248\n",
            "0.6152284992315684 \t 0.6209425 \tdiff: 0.005713974179991643\n",
            "correctness: 99.0909090909091 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtFrL1eatmen"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOh6GYg3tmKY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpPaXEfmtl-r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}